{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # 数据处理包\n",
    "import numpy as np  # 数据处理包\n",
    "from sklearn.metrics import roc_auc_score  # roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 300), (100000, 300))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(-999) ### 填充特殊值\n",
    "test = test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [x for x in train.columns if x not in ['id','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['label'].values\n",
    "X = train[feats].values\n",
    "test_id = test['id'].values\n",
    "X_test = test[feats].values\n",
    "y_test  = test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入五折工具及各个模型\n",
    "from sklearn.model_selection import StratifiedKFold  # 数据切分、分层五折验证包\n",
    "import lightgbm as lgb  # lgb模型 ,安装的方法是在anaconda promote里，直接pip install lightgbm 即可\n",
    "import xgboost as xgb  # xgb模型，安装的方法是在anaconda promote里，直接pip install xgboost 即可，和lightgbm一样\n",
    "# 设置skf\n",
    "data_seed = 2020\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=data_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb和xgb的参数\n",
    "lgb_params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.06,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'feature_fraction': 0.8,\n",
    "    'feature_fraction_seed': 300, ### 特征抽样的随机种子\n",
    "    'bagging_seed': 3, ### 数据抽样的随机种子,取10个不同的，然后对结果求平均,todo:求出10个结果，然后求平均\n",
    "    #'is_unbalance': True   #### 第一种方法：设置is_unbalance为True，表明传入的数据集是类别不平衡的\n",
    "    #'scale_pos_weight': 98145/1855###负样本数量/正样本数量 -> scale_pos_weight * 正样本 == 负样本\n",
    "}\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',  ##提升类型\n",
    "    'objective': 'binary:logistic',  ###目标函数\n",
    "    'eval_metric': 'auc',  ##评价函数\n",
    "    'eta': 0.1,  ### 学习率 ，一般0.0几\n",
    "    'max_depth': 6,  ###树最大深度\n",
    "    'min_child_weight': 1,  ###最小样本二阶梯度权重, 取值是整数\n",
    "    'subsample': 1.0,  ###训练数据采样 ,取值0.0~1.0之间\n",
    "    'colsample_bytree': 1.0,  ###训练特征采样，取值0.0~1.0之间\n",
    "    'lambda': 1,  ## l2正则，取值是整数\n",
    "    'alpha': 0,   ### l1正则，取值整数\n",
    "    'silent': 1   ### 取值1控制xgboost训练信息不输出\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_train = pd.DataFrame()  # 定义df数据，以便做融合\n",
    "blend_test = pd.DataFrame()  # 定义df数据，以便做融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training fold:  1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.971437\n",
      "[100]\tvalid_0's auc: 0.976224\n",
      "[150]\tvalid_0's auc: 0.977292\n",
      "[200]\tvalid_0's auc: 0.977833\n",
      "[250]\tvalid_0's auc: 0.977789\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's auc: 0.977946\n",
      "auc score:  0.9779461572822764\n",
      "training fold:  2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.976491\n",
      "[100]\tvalid_0's auc: 0.977797\n",
      "[150]\tvalid_0's auc: 0.9778\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.978142\n",
      "auc score:  0.9781421102694882\n",
      "training fold:  3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.976192\n",
      "[100]\tvalid_0's auc: 0.978029\n",
      "[150]\tvalid_0's auc: 0.979202\n",
      "[200]\tvalid_0's auc: 0.979367\n",
      "[250]\tvalid_0's auc: 0.979628\n",
      "[300]\tvalid_0's auc: 0.97977\n",
      "[350]\tvalid_0's auc: 0.979687\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's auc: 0.979878\n",
      "auc score:  0.9798779488899133\n",
      "training fold:  4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.979365\n",
      "[100]\tvalid_0's auc: 0.981435\n",
      "[150]\tvalid_0's auc: 0.98168\n",
      "[200]\tvalid_0's auc: 0.982358\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's auc: 0.982363\n",
      "auc score:  0.9823631326057944\n",
      "training fold:  5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.975405\n",
      "[100]\tvalid_0's auc: 0.977893\n",
      "[150]\tvalid_0's auc: 0.978275\n",
      "[200]\tvalid_0's auc: 0.978126\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.978313\n",
      "auc score:  0.9783132086731785\n"
     ]
    }
   ],
   "source": [
    "# 训练lgb，用作第一层模型中的其中一个\n",
    "test_pred_lgb = 0  # 预测结果存放对象\n",
    "cv_score_lgb = []  # 存放每次auc的对象\n",
    "train_feats = np.zeros(X.shape[0])  # 整体训练的样本数量\n",
    "for idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    print('training fold: ', idx + 1)  # 遍历的第几次\n",
    "    train_x, valid_x = X[train_idx], X[test_idx]  # 拆分成训练集和验证集\n",
    "    train_y, valid_y = y[train_idx], y[test_idx]  # 拆分成训练集和验证集\n",
    "    dtrain = lgb.Dataset(train_x, train_y, feature_name=feats)  # 组成训练集\n",
    "    dvalid = lgb.Dataset(valid_x, valid_y, feature_name=feats)  # 组成验证集\n",
    "    model = lgb.train(lgb_params, dtrain, num_boost_round=2000, valid_sets=dvalid, early_stopping_rounds=50, verbose_eval=50)  # 定义lgb模型\n",
    "\n",
    "    valid_pred = model.predict(valid_x, num_iteration=model.best_iteration)  # 当前模型最佳参数并预测，num_iteration：选择最优的lgb\n",
    "    train_feats[test_idx] = valid_pred  # 每次把验证集的结果填入，做训练的结果集，由于是5折，所以每次都是1/5的数据，把它们当作lgb训练集特征\n",
    "    auc_score = roc_auc_score(valid_y, valid_pred)  # 计算auc\n",
    "    print('auc score: ', auc_score)\n",
    "    cv_score_lgb.append(auc_score)  # 存放验证集auc值\n",
    "    test_pred_lgb += model.predict(X_test, num_iteration=model.best_iteration)  # 预测结果并累加，做预测的结果集，把它们当作lgb测试集当作特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69777395e-04, 7.61534609e-04, 4.87054815e-03, ...,\n",
       "       5.55546514e-02, 3.93865215e-02, 5.10414655e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats  # 训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.62077794e-04, 6.29276400e-04, 3.35815479e-03, ...,\n",
       "       4.64100502e-01, 3.11100442e-01, 6.07412241e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_lgb /= 5\n",
    "test_pred_lgb  # 测试的结果，由于测试的结果是5折每次的累加，所以需要除于5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练结果和预测结果加入到blend数据集\n",
    "blend_train['lgb_feat'] = train_feats\n",
    "blend_test['lgb_feat'] = test_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training fold:  1\n",
      "[0]\teval-auc:0.902923\n",
      "Will train until eval-auc hasn't improved in 50 rounds.\n",
      "[50]\teval-auc:0.970518\n",
      "[100]\teval-auc:0.972938\n",
      "Stopping. Best iteration:\n",
      "[73]\teval-auc:0.972938\n",
      "\n",
      "auc score:  0.9728734878354665\n",
      "training fold:  2\n",
      "[0]\teval-auc:0.890585\n",
      "Will train until eval-auc hasn't improved in 50 rounds.\n",
      "[50]\teval-auc:0.976147\n",
      "[100]\teval-auc:0.977656\n",
      "Stopping. Best iteration:\n",
      "[65]\teval-auc:0.977656\n",
      "\n",
      "auc score:  0.9775689443489396\n",
      "training fold:  3\n",
      "[0]\teval-auc:0.903571\n",
      "Will train until eval-auc hasn't improved in 50 rounds.\n",
      "[50]\teval-auc:0.975988\n",
      "[100]\teval-auc:0.976093\n",
      "Stopping. Best iteration:\n",
      "[64]\teval-auc:0.976212\n",
      "\n",
      "auc score:  0.9760364052362702\n",
      "training fold:  4\n",
      "[0]\teval-auc:0.912538\n",
      "Will train until eval-auc hasn't improved in 50 rounds.\n",
      "[50]\teval-auc:0.978535\n",
      "[100]\teval-auc:0.979904\n",
      "Stopping. Best iteration:\n",
      "[60]\teval-auc:0.980012\n",
      "\n",
      "auc score:  0.9799886959706327\n",
      "training fold:  5\n",
      "[0]\teval-auc:0.902044\n",
      "Will train until eval-auc hasn't improved in 50 rounds.\n",
      "[50]\teval-auc:0.97681\n",
      "[100]\teval-auc:0.978548\n",
      "Stopping. Best iteration:\n",
      "[67]\teval-auc:0.978586\n",
      "\n",
      "auc score:  0.9784056924411445\n"
     ]
    }
   ],
   "source": [
    "# 训练xgb，用作第一层模型中的其中一个\n",
    "test_pred_xgb = 0 # 预测结果存放对象\n",
    "cv_score_xgb = []  # 存放每次auc的对象\n",
    "train_feats_xgb = np.zeros(X.shape[0])  # 整体训练的样本数量\n",
    "for idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    print('training fold: ', idx + 1) # 遍历的第几次\n",
    "    train_x, valid_x = X[train_idx], X[test_idx]  # 拆分成训练集和验证集\n",
    "    train_y, valid_y = y[train_idx], y[test_idx]  # 拆分成训练集和验证集\n",
    "    dtrain = xgb.DMatrix(train_x, train_y, feature_names=feats)  # 组成训练集\n",
    "    dvalid = xgb.DMatrix(valid_x, valid_y, feature_names=feats)  # 组成验证集\n",
    "    watchlist = [(dvalid, 'eval')]\n",
    "    model = xgb.train(xgb_params, dtrain, num_boost_round=2000, evals=watchlist, early_stopping_rounds=50, verbose_eval=50)  # 定义xgb模型\n",
    "\n",
    "    valid_pred = model.predict(dvalid, ntree_limit=model.best_iteration)  # 当前模型最佳参数并预测，ntree_limit：选择最优的xgb\n",
    "    train_feats_xgb[test_idx] = valid_pred  # 每次把验证集的结果填入，做训练的结果集，由于是5折，所以每次都是1/5的数据\n",
    "    auc_score = roc_auc_score(valid_y, valid_pred)  # 计算auc\n",
    "    print('auc score: ', auc_score)\n",
    "    cv_score_xgb.append(auc_score)  # 存放验证集auc值\n",
    "    dtest = xgb.DMatrix(X_test,feature_names=feats)  ##同时指定特征名字\n",
    "    test_pred_xgb += model.predict(dtest, ntree_limit=model.best_iteration)  # 预测结果并累加，做预测的结果集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00127854, 0.00197552, 0.01527219, ..., 0.06836488, 0.10070858,\n",
       "       0.64704806])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats_xgb  # 训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00025571, 0.0003951 , 0.00305444, ..., 0.01367298, 0.02014172,\n",
       "       0.12940961])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats_xgb /= 5  # 测试的结果，由于测试的结果是5折每次的累加，所以需要除于5\n",
    "train_feats_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练结果和预测结果加入到blend数据集\n",
    "blend_train['xgb_feat'] = train_feats_xgb\n",
    "blend_test['xgb_feat'] = test_pred_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb_feat</th>\n",
       "      <th>xgb_feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.003054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lgb_feat  xgb_feat\n",
       "0  0.000170  0.000256\n",
       "1  0.000762  0.000395\n",
       "2  0.004871  0.003054\n",
       "3  0.002038  0.001449\n",
       "4  0.000674  0.000797"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb_feat</th>\n",
       "      <th>xgb_feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.008366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.008058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.064686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.044280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.018679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lgb_feat  xgb_feat\n",
       "0  0.000362  0.008366\n",
       "1  0.000629  0.008058\n",
       "2  0.003358  0.064686\n",
       "3  0.004139  0.044280\n",
       "4  0.000489  0.018679"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # 载入lr模型，这里lr模型用作第二层模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(blend_train.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.63761109, 10.70603716]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coef_  # 特征权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_lr = lr_model.predict_proba(blend_test.values)[:,1]  # 第二层模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaderboard_score(test_df,prediction):\n",
    "    \"\"\"\n",
    "    定义评分函数\n",
    "    test_df: 测试集\n",
    "    prediction: 预测结果\n",
    "    reture: 输出结果分数\n",
    "    \"\"\"\n",
    "    label = test_df['label'].values  # 拿出真实样本\n",
    "    assert len(prediction) == len(label)  # 断言其长度相等\n",
    "    print('stacking auc score: ', roc_auc_score(label, prediction))  # 计算评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online auc score:  0.9941125561099089\n"
     ]
    }
   ],
   "source": [
    "get_leaderboard_score(test,test_pred_lr)  # stacking模型的分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online auc score:  0.9985280429047785\n"
     ]
    }
   ],
   "source": [
    "get_leaderboard_score(test,test_pred_lgb)  # lgb模型的分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online auc score:  0.9902076703441838\n"
     ]
    }
   ],
   "source": [
    "get_leaderboard_score(test,test_pred_xgb)  # xgb模型的分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9793285115441301, 0.0016649382928107428)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_score_lgb), np.std(cv_score_lgb) # lgb验证集评分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型简单加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_result = 0.5 * test_pred_lgb + 0.5 * test_pred_xgb  # 模型平均加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online auc score:  0.9946536225418163\n"
     ]
    }
   ],
   "source": [
    "get_leaderboard_score(test,blend_result)  # 加权模型分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
